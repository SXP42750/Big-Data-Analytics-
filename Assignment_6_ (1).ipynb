{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XdNlr5jSYWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec468584-731d-41c4-9b93-650f9abd603a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/drive/MyDrive/diabetes(1).csv'"
      ],
      "metadata": {
        "id": "_r3MUyfgE-IQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "loss, accuracy = my_first_nn.evaluate(X_test, Y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:',accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1E84srQrF1w",
        "outputId": "e0f1f7a7-f4c0-4df9-eae2-ca26d294562a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 4ms/step - loss: 14.4002 - acc: 0.3576\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 4.2553 - acc: 0.5208\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5111 - acc: 0.6615\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8484 - acc: 0.6094\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6477 - acc: 0.6042\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4231 - acc: 0.5955\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2509 - acc: 0.6094\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1192 - acc: 0.6059\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0268 - acc: 0.6285\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9605 - acc: 0.6198\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9267 - acc: 0.6319\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8691 - acc: 0.6128\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8375 - acc: 0.6389\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8064 - acc: 0.6510\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7736 - acc: 0.6354\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7804 - acc: 0.6372\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7448 - acc: 0.6597\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7264 - acc: 0.6580\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7120 - acc: 0.6649\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7121 - acc: 0.6580\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.6528\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6804 - acc: 0.6753\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6814 - acc: 0.6615\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6741 - acc: 0.6788\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6676 - acc: 0.6632\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6626 - acc: 0.6701\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.6667\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6788\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.6823\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6315 - acc: 0.6997\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6328 - acc: 0.6892\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6255 - acc: 0.6997\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6375 - acc: 0.6701\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6522 - acc: 0.6458\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6209 - acc: 0.6788\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6351 - acc: 0.6875\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5972 - acc: 0.7083\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5997 - acc: 0.6997\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5912 - acc: 0.6979\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - acc: 0.6944\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5905 - acc: 0.6840\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5974 - acc: 0.6927\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5961 - acc: 0.6997\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5872 - acc: 0.6997\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - acc: 0.7031\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5823 - acc: 0.7031\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5638 - acc: 0.7222\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5897 - acc: 0.6962\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.5611 - acc: 0.7188\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - acc: 0.6997\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5944 - acc: 0.7361\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5685 - acc: 0.7135\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5774 - acc: 0.7222\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5745 - acc: 0.7257\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5885 - acc: 0.7222\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - acc: 0.7135\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - acc: 0.7153\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - acc: 0.7066\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - acc: 0.7188\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5837 - acc: 0.6927\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5861 - acc: 0.7066\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.6944\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5607 - acc: 0.7118\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5480 - acc: 0.7170\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - acc: 0.7222\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - acc: 0.7240\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - acc: 0.7309\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.7170\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5652 - acc: 0.7205\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5477 - acc: 0.7170\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.7083\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - acc: 0.7049\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5990 - acc: 0.7066\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - acc: 0.7326\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.7465\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5396 - acc: 0.7448\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5726 - acc: 0.7240\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - acc: 0.7326\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - acc: 0.7361\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - acc: 0.7066\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5451 - acc: 0.7344\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5576 - acc: 0.7101\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - acc: 0.7431\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - acc: 0.7292\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5421 - acc: 0.7413\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5478 - acc: 0.7344\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - acc: 0.7205\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - acc: 0.7378\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - acc: 0.7274\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5441 - acc: 0.7309\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5356 - acc: 0.7309\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5346 - acc: 0.7326\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5429 - acc: 0.7465\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5348 - acc: 0.7326\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5338 - acc: 0.7292\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5374 - acc: 0.7344\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5200 - acc: 0.7309\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5454 - acc: 0.7396\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5272 - acc: 0.7396\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5184 - acc: 0.7396\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6037 - acc: 0.6927\n",
            "Loss: 0.6036500930786133\n",
            "Accuracy: 0.6927083134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# load dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "#split the dataset with training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8], test_size=0.1, random_state=30)\n",
        "\n",
        "np.random.seed(155)\n",
        "\n",
        "my_first_nn = Sequential()\n",
        "my_first_nn.add(Dense(64, activation='relu', input_shape=(8,))) #   Hidden Layer\n",
        "my_first_nn.add(Dense(8, activation='relu'))  # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(64, activation='relu'))  #hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "my_first_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "loss, accuracy = my_first_nn.evaluate(X_test, Y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:',accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuzHorBiDciq",
        "outputId": "c5e0cf34-e775-49a8-e6dd-3fb380e0328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 4s 4ms/step - loss: 0.4294 - accuracy: 0.5094\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.6483\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2249 - accuracy: 0.6527\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2185 - accuracy: 0.6715\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2261 - accuracy: 0.6686\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.6889\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2085 - accuracy: 0.6831\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.6845\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.6744\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.6918\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.6990\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.6599\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.7106\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.7033\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.7120\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.7178\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.7337\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.7250\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.7135\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.7395\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.7366\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.7496\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1817 - accuracy: 0.7279\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.7192\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.7106\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.7294\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.7482\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.7221\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.7236\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.7424\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.7438\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.7467\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.7467\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.7482\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.7352\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.7525\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.7525\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.7569\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.7598\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.7583\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.7496\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.7482\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1718 - accuracy: 0.7511\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.7554\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.7612\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.7453\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.7525\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.7511\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.7627\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.7569\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.7496\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.7598\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.7656\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.7656\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.7540\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.7656\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.7815\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.7699\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.7685\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1597 - accuracy: 0.7887\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.7670\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.7656\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.7728\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.7771\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.7815\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.7641\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.7757\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.7844\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.7786\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.7829\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.7945\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.7598\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.7728\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.7800\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.7757\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.7858\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.7771\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.7829\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.7945\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.7699\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.7757\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.7757\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1616 - accuracy: 0.7713\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.7873\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.7887\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.8017\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.7931\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.7742\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1538 - accuracy: 0.7742\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.7612\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.7873\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.7858\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.7887\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1557 - accuracy: 0.7829\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.7699\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.8032\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.8032\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1540 - accuracy: 0.7858\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.7873\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.8017\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1886 - accuracy: 0.7143\n",
            "Loss: 0.18862342834472656\n",
            "Accuracy: 0.7142857313156128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))  # Hidden layer\n",
        "model.add(Dense(512, activation='relu'))  #Hidden layer\n",
        "model.add(Dense(30, activation='sigmoid')) #Hidden layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "id": "I4u9DPNWR4Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96bc1db-0b2b-4574-bc3c-4d796c39e799"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 5ms/step - loss: 0.6201 - accuracy: 0.8686 - val_loss: 0.2587 - val_accuracy: 0.9403\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9565 - val_loss: 0.1367 - val_accuracy: 0.9649\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9732 - val_loss: 0.1204 - val_accuracy: 0.9661\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0928 - val_accuracy: 0.9728\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9741\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.0736 - val_accuracy: 0.9785\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.0761 - val_accuracy: 0.9766\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0748 - val_accuracy: 0.9790\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0787 - val_accuracy: 0.9794\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0760 - val_accuracy: 0.9799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))  # Hidden layer\n",
        "model.add(Dense(512, activation='relu'))  #Hidden layer\n",
        "model.add(Dense(30, activation='sigmoid')) #Hidden layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a45404d-1ee8-4c4f-93ef-e5d2f6b283b0",
        "id": "Pp_NqUehqe-b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 2s 5ms/step - loss: 1.0116 - accuracy: 0.7610 - val_loss: 0.4758 - val_accuracy: 0.8967\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.9235 - val_loss: 0.2526 - val_accuracy: 0.9362\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9390 - val_loss: 0.2023 - val_accuracy: 0.9449\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1995 - accuracy: 0.9466 - val_loss: 0.1851 - val_accuracy: 0.9503\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1830 - accuracy: 0.9498 - val_loss: 0.1856 - val_accuracy: 0.9498\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9537 - val_loss: 0.1720 - val_accuracy: 0.9553\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1704 - accuracy: 0.9537 - val_loss: 0.1840 - val_accuracy: 0.9468\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1665 - accuracy: 0.9537 - val_loss: 0.1578 - val_accuracy: 0.9564\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.9550 - val_loss: 0.1694 - val_accuracy: 0.9522\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1542 - accuracy: 0.9582 - val_loss: 0.1628 - val_accuracy: 0.9574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select a random image from the test data\n",
        "test_image_index = np.random.randint(0, len(test_data))\n",
        "test_image = test_data[test_image_index]\n",
        "\n",
        "# reshape the image to its original shape\n",
        "test_image = test_image.reshape((28, 28))\n",
        "\n",
        "# plot the image\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title('Test image')\n",
        "plt.show()\n",
        "# make a prediction on the test image\n",
        "prediction = model.predict(test_image.reshape((1, dimData)))\n",
        "\n",
        "# get the predicted class label\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# print the predicted class label\n",
        "print('Predicted class:', predicted_class)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select a random image from the test data\n",
        "test_image_index = np.random.randint(0, len(test_data))\n",
        "test_image = test_data[test_image_index]\n",
        "\n",
        "# reshape the image to its original shape\n",
        "test_image = test_image.reshape((28, 28))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "fYY3Fd4xkRds",
        "outputId": "41ee68f7-c413-4e95-ce35-25a6f25f2efd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted class: 3\n"
          ]
        }
      ]
    }
  ]
}